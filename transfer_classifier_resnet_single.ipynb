{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /usr/remote/anaconda-3.7-2020-05-28/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import h5py\n",
    "import deepdish as dd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f87a0136210>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "batch_size_train = 4# was 64\n",
    "batch_size_test = 4\n",
    "learning_rate = 0.001\n",
    "momentum = 0.1\n",
    "log_interval = 31\n",
    "tt_factor = 0.8\n",
    "orientation = 'AP'\n",
    "num_imgs = 2500\n",
    "\n",
    "random_seed = 1\n",
    "#torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    NOTES: \n",
    "    - it's \"No Finding\" not \"No findings\"\n",
    "    - it's \"Pleural_Thickening\" not \"Pleural_thickening\"\n",
    "    - it's not \"Nodule Mass\", but rather \"Nodule\" and \"Mass\" separately\n",
    "'''\n",
    "disease_map = {\"Atelectasis\" : 0, \"Consolidation\" : 1, \"Infiltration\" : 2, \"Pneumothorax\": 3, \"Edema\": 4,\n",
    "               \"Emphysema\": 5, \"Fibrosis\": 6, \"Effusion\" : 7, \"Pneumonia\" : 8, \"Pleural_Thickening\" : 9,\n",
    "               \"Cardiomegaly\" : 10, \"Nodule\" : 11, \"Mass\" : 12, \"Hernia\" : 13, \"No Finding\" : 14 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLoader(torch.utils.data.Dataset):\n",
    "    '''\n",
    "        Params: data - the data dictionary\n",
    "                view - the orientation you want to look at\n",
    "                diseases - the diseases you would like to look at\n",
    "                num_imgs - the number of images of each disease you would like\n",
    "                factor - the ratio of training and testing data\n",
    "                typ - 0 for training, 1 for testing\n",
    "    '''\n",
    "    def __init__(self, data, view, diseases, num_imgs, factor, typ, transforms=None):\n",
    "        \n",
    "        #private data\n",
    "        self.root = os.path.join('data/sorted_images',)\n",
    "        self.data = data # dict object\n",
    "        self.transforms = transforms\n",
    "        self.len_data = 0\n",
    "        datalist = []\n",
    "        \n",
    "        #Creating the datalist\n",
    "        for i in range(len(diseases)):\n",
    "            if len(data[view][diseases[i]]) <= num_imgs: #if the folder has less images than the desired number of images\n",
    "                if typ == 0:\n",
    "                    start = 0\n",
    "                    end = int(len(data[view][diseases[i]])*factor)\n",
    "                else:\n",
    "                    start = int(len(data[view][diseases[i]])*factor)\n",
    "                    end = -1\n",
    "            else:\n",
    "                if typ == 0:\n",
    "                    start = 0\n",
    "                    end = int(num_imgs*factor)\n",
    "                else:\n",
    "                    start = int(num_imgs*factor)\n",
    "                    end = num_imgs\n",
    "            datalist.append(self.data[view][diseases[i]][start:end])\n",
    "        \n",
    "        for item in datalist:\n",
    "            self.len_data += len(item)\n",
    "        \n",
    "        \n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "        \n",
    "        for dis in datalist:\n",
    "            for data in dis:\n",
    "                #creating the image path\n",
    "                data['img_path'] = os.path.join(self.root, data['classes'][0], view, data['img_name'])            \n",
    "                diseases = data['classes']\n",
    "                \n",
    "                # TODO: we want the 1-hot vector for full-class net, not for 1 class net\n",
    "                # what is below is very much hardcoded\n",
    "#                 if data['classes'][0] != \"No Finding\":\n",
    "#                     label = 1\n",
    "#                 else:\n",
    "#                     label = 0\n",
    "                \n",
    "                # label = torch.Tensor([label])\n",
    "\n",
    "                one_hot = [0] * 15\n",
    "            \n",
    "                for c in data['classes']:\n",
    "                    hot_index = disease_map[c]\n",
    "                    one_hot[hot_index] = 1\n",
    "                    \n",
    "                label = torch.Tensor(one_hot)\n",
    "                \n",
    "                #modifying the attributes\n",
    "                self.img_paths.append(data['img_path'])\n",
    "                self.img_labels.append(label)\n",
    "                # self.img_labels.append(data['label_tensor'])\n",
    "            \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        img_path, img_label = self.img_paths[item], self.img_labels[item]\n",
    "  \n",
    "        # TODO: fix this hot fix -> recreate data object with underscore in name\n",
    "        img_path = img_path.replace('No Finding', 'No_Finding')\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            img_path = img_path.replace('/AP/', '/PA/')\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        self.cur_img_path = img_path\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            for t in self.transforms:\n",
    "                img = t(img)         \n",
    "\n",
    "        return img, img_label\n",
    "    \n",
    "    def get_img_path(self):\n",
    "        return self.cur_img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded in successfully\n"
     ]
    }
   ],
   "source": [
    "pkl_load = open('dataset.pickle', 'rb')\n",
    "data = pkl.load(pkl_load)\n",
    "pkl_load.close()\n",
    "print(\"data loaded in successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', 'Hernia', 'No Finding'])\n"
     ]
    }
   ],
   "source": [
    "print(data['AP'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20078\n",
      "5014\n"
     ]
    }
   ],
   "source": [
    "transforms = [torchvision.transforms.ToTensor()] # no longer grayscale conversion\n",
    "#0 = train, 1 = test\n",
    "dataset_train = GetLoader(data, orientation, ['Atelectasis', 'Consolidation', 'Infiltration', \n",
    "                                              'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', \n",
    "                                              'Effusion', 'Pneumonia', 'Pleural_Thickening', \n",
    "                                              'Cardiomegaly', 'Nodule', 'Mass', 'Hernia', 'No Finding'],\n",
    "                          num_imgs, tt_factor, 0, transforms)\n",
    "dataset_test = GetLoader(data, orientation, ['Atelectasis', 'Consolidation', 'Infiltration', \n",
    "                                              'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', \n",
    "                                              'Effusion', 'Pneumonia', 'Pleural_Thickening', \n",
    "                                              'Cardiomegaly', 'Nodule', 'Mass', 'Hernia', 'No Finding'],\n",
    "                          num_imgs, tt_factor, 1, transforms)\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5020\n",
      "1254\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size_train, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size_train, shuffle=True, num_workers=1)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/npp002/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'vgg11', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Sequential(*[\n",
    "    nn.Linear(in_features=4096, out_features=500, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=500, out_features=15, bias=True),\n",
    "    nn.Sigmoid()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0, 3, 6, 8, 11, 13, 16, 18]\n",
    "outs_per_layer = [64, 128, 256, 256, 512, 512, 512, 512]\n",
    "for i, out_f in zip(layers, outs_per_layer):\n",
    "    model.features[i] = nn.Sequential(*[model.features[i], nn.BatchNorm2d(out_f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=500, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=500, out_features=15, bias=True)\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 130827855\n"
     ]
    }
   ],
   "source": [
    "network = model\n",
    "#network = torchvision.models.vgg11(pretrained=False)\n",
    "#network.fc = nn.Linear(512, 15)\n",
    "network = torch.nn.DataParallel(network)\n",
    "network.cuda()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "print('Trainable params: {}'.format(sum(p.numel() for p in network.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source: https://gist.github.com/the-bass/cae9f3976866776dea17a5049013258d\n",
    "def hard_binary_accuracy(batch, labels):\n",
    "    batch = torch.round(batch)\n",
    "    confusion_matrix = batch / labels\n",
    "    \n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_matrix = batch / labels\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_matrix == 1).item()\n",
    "    false_positives = torch.sum(confusion_matrix == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_matrix)).item()\n",
    "    false_negatives = torch.sum(confusion_matrix == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0, 4, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor([[[1, 1], [0, 0]], \n",
    "                  [[1, 1], [0, 0]]])\n",
    "\n",
    "l = torch.Tensor([[[1, 1], [0, 0]], \n",
    "                  [[1, 1], [0, 0]]])\n",
    "hard_binary_accuracy(b, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pred_conversion(batch, label):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    network.train()\n",
    "    train_losses = []\n",
    "    num_tested = 0\n",
    "    net_loss = 0\n",
    "    \n",
    "    total_true_pos, total_false_pos, total_true_neg, total_false_neg = 0, 0, 0, 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # (output - actual )\n",
    "        \n",
    "        if torch.cuda.is_available:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = network(data)\n",
    "        \n",
    "        criterion = torch.nn.BCELoss()  # 1 0 1 0 0 0 \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        net_loss += loss.detach().cpu().item()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        num_tested += len(data)\n",
    "        \n",
    "        #if True or batch_idx == len(train_loader) - 1:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = output.detach().clone().cpu()\n",
    "        target = target.cpu()\n",
    "\n",
    "        true_pos, false_pos, true_neg, false_neg = hard_binary_accuracy(pred, target)\n",
    "        total_true_pos += true_pos\n",
    "        total_false_pos += false_pos\n",
    "        total_true_neg += true_neg\n",
    "        total_false_neg += false_neg\n",
    "            \n",
    "        \n",
    "    net_loss /= len(train_loader)\n",
    "    return net_loss, total_true_pos, total_false_pos, total_true_neg, total_false_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    network.eval()\n",
    "    test_losses = []\n",
    "    net_loss = 0    \n",
    "\n",
    "    total_true_pos, total_false_pos, total_true_neg, total_false_neg = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            if torch.cuda.is_available:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = network(data)\n",
    "            criterion = torch.nn.BCELoss()\n",
    "            net_loss += criterion(output, target).item()\n",
    "\n",
    "            pred = output.detach().clone().cpu()\n",
    "            target = target.cpu()\n",
    "            \n",
    "            true_pos, false_pos, true_neg, false_neg = hard_binary_accuracy(pred, target)\n",
    "            total_true_pos += true_pos\n",
    "            total_false_pos += false_pos\n",
    "            total_true_neg += true_neg\n",
    "            total_false_neg += false_neg\n",
    "            \n",
    "        \n",
    "    net_loss /= len(train_loader)\n",
    "    return net_loss, total_true_pos, total_false_pos, total_true_neg, total_false_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GeForce RTX 2080 Ti\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20080 5016\n"
     ]
    }
   ],
   "source": [
    "train_sample_size = len(train_loader) * batch_size_train\n",
    "test_sample_size = len(test_loader) * batch_size_test\n",
    "print(train_sample_size, test_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "-----------Epoch 1 (time = 1837.74 s  aka   30.63  mins) ----------------\n",
      "Train set: Avg. loss: 0.3918,  Accuracy: 257921/301200 (85.63%)\n",
      "\n",
      "          True Positive: 0.41%\n",
      "          True Negative: 85.22%\n",
      "          False Positive: 1.65%\n",
      "          False Negative 12.71%\n",
      "          \n",
      "\n",
      "Test set:  Avg. loss: 0.0901, Accuracy: 64925/75240 (86.29%)\n",
      "\n",
      "          True Positive: 0.00%\n",
      "          True Negative: 86.29%\n",
      "          False Positive: 0.00%\n",
      "          False Negative 13.67%\n",
      "          \n",
      "-----------Epoch 2 (time = 1837.96 s  aka   30.63  mins) ----------------\n",
      "Train set: Avg. loss: 0.3609,  Accuracy: 261535/301200 (86.83%)\n",
      "\n",
      "          True Positive: 0.03%\n",
      "          True Negative: 86.80%\n",
      "          False Positive: 0.07%\n",
      "          False Negative 13.08%\n",
      "          \n",
      "\n",
      "Test set:  Avg. loss: 0.0892, Accuracy: 64925/75240 (86.29%)\n",
      "\n",
      "          True Positive: 0.00%\n",
      "          True Negative: 86.29%\n",
      "          False Positive: 0.00%\n",
      "          False Negative 13.67%\n",
      "          \n",
      "Training complete (time = 3675.71 s)\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "begin_time = time.time()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "train_true_pos = []\n",
    "train_false_pos = []\n",
    "train_true_neg = []\n",
    "train_false_neg = []\n",
    "\n",
    "test_true_pos = []\n",
    "test_false_pos = []\n",
    "test_true_neg = []\n",
    "test_false_neg = []\n",
    "\n",
    "\n",
    "\n",
    "# patience_limit = 25\n",
    "# patience = 0\n",
    "# min_test_loss = 10\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    loss_train, true_pos_train, false_pos_train, true_neg_train, false_neg_train = train(epoch)\n",
    "    loss_test, true_pos_test, false_pos_test, true_neg_test, false_neg_test = test()\n",
    "    \n",
    "#     print(\"tp / fp / tn / fn : \", true_pos_test, false_pos_test, true_neg_test, false_neg_test )\n",
    "    train_losses.append(loss_train)\n",
    "    test_losses.append(loss_test)\n",
    "    \n",
    "    n_correct_train = true_pos_train + true_neg_train\n",
    "    n_correct_test = true_pos_test + true_neg_test\n",
    "    \n",
    "    acc_train = 100. * n_correct_train / (train_sample_size * 15)\n",
    "    acc_test = 100. * n_correct_test / (test_sample_size * 15)\n",
    "    \n",
    "    train_acc.append(acc_train)\n",
    "    test_acc.append(acc_test)\n",
    "    \n",
    "    true_pos_rate_train = 100. * true_pos_train / (train_sample_size * 15)\n",
    "    true_neg_rate_train = 100. * true_neg_train / (train_sample_size * 15)\n",
    "    false_pos_rate_train = 100. * false_pos_train / (train_sample_size * 15)\n",
    "    false_neg_rate_train = 100. * false_neg_train / (train_sample_size * 15)\n",
    "    \n",
    "    true_pos_rate_test = 100. * true_pos_test / (test_sample_size * 15)\n",
    "    true_neg_rate_test = 100. * true_neg_test / (test_sample_size * 15)\n",
    "    false_pos_rate_test = 100. * false_pos_test / (test_sample_size * 15)\n",
    "    false_neg_rate_test = 100. * false_neg_test / (test_sample_size * 15)\n",
    "\n",
    "    train_true_pos.append(true_pos_train)\n",
    "    train_false_pos.append(false_pos_train)\n",
    "    train_true_neg.append(true_neg_train)\n",
    "    train_false_neg.append(false_neg_train)\n",
    "\n",
    "    test_true_pos.append(true_pos_test)\n",
    "    test_false_pos.append(false_pos_test)\n",
    "    test_true_neg.append(true_neg_test)\n",
    "    test_false_neg.append(false_neg_test)\n",
    "        \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(\"-----------Epoch \" + str(epoch) + \" (time =\", round(elapsed_time, 2), \"s  aka  \", round(elapsed_time / 60, 2), \" mins) ----------------\")\n",
    "    print('Train set: Avg. loss: {:.4f},  Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        loss_train, n_correct_train, train_sample_size * 15, acc_train))\n",
    "    print('''\n",
    "          True Positive: {:.2f}%\n",
    "          True Negative: {:.2f}%\n",
    "          False Positive: {:.2f}%\n",
    "          False Negative {:.2f}%\n",
    "          '''.format(true_pos_rate_train, true_neg_rate_train, false_pos_rate_train, false_neg_rate_train))    \n",
    "    print('\\nTest set:  Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        loss_test, n_correct_test, test_sample_size * 15, acc_test))\n",
    "    print('''\n",
    "          True Positive: {:.2f}%\n",
    "          True Negative: {:.2f}%\n",
    "          False Positive: {:.2f}%\n",
    "          False Negative {:.2f}%\n",
    "          '''.format(true_pos_rate_test, true_neg_rate_test, false_pos_rate_test, false_neg_rate_test))\n",
    "    \n",
    "end_time = time.time() - begin_time\n",
    "\n",
    "print(\"Training complete (time =\", round(end_time, 2), \"s)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.plot(train_losses, \"-b\",  label=\"train\")\n",
    "plt.plot(test_losses, \"-r\", label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.plot(train_acc, \"-b\", label=\"train\")\n",
    "plt.plot(test_acc, \"-r\", label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(network.state_dict(), \n",
    "#            os.path.join('/home/nick/workspace/saved_models/classifier_nodule.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
